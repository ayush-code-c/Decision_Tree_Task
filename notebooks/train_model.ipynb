{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded.\n",
      "Testing with 1000 rows (subset of the data).\n",
      "Max depth: 2, Min size: 300\n",
      "Decision Tree trained on the subset of data.\n",
      "Model saved to ../models/decision_tree_model_test.pkl\n",
      "Prediction for the first row: 0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle  # For saving and loading models\n",
    "\n",
    "# Calculate the Gini Index for a list of class labels\n",
    "def gini_index(groups, classes):\n",
    "    total_samples = sum(len(group) for group in groups)\n",
    "    gini = 0.0\n",
    "    for group in groups:\n",
    "        size = len(group)\n",
    "        if size == 0:\n",
    "            continue\n",
    "        class_counts = np.bincount(group[:, -1].astype(int), minlength=len(classes))\n",
    "        proportions = class_counts / size\n",
    "        gini += (1.0 - np.sum(proportions ** 2)) * (size / total_samples)\n",
    "    return gini\n",
    "\n",
    "# Split a dataset based on an attribute and attribute value\n",
    "def test_split(index, value, dataset):\n",
    "    left = dataset[dataset[:, index] < value]\n",
    "    right = dataset[dataset[:, index] >= value]\n",
    "    return left, right\n",
    "\n",
    "# Select the best split point for a dataset\n",
    "def get_split(dataset):\n",
    "    class_values = np.unique(dataset[:, -1])  # Unique class labels\n",
    "    best_index, best_value, best_score, best_groups = None, None, float('inf'), None\n",
    "    \n",
    "    for index in range(dataset.shape[1] - 1):\n",
    "        for row in dataset:\n",
    "            groups = test_split(index, row[index], dataset)\n",
    "            gini = gini_index(groups, class_values)\n",
    "            if gini < best_score:\n",
    "                best_index, best_value, best_score, best_groups = index, row[index], gini, groups\n",
    "    \n",
    "    return {'index': best_index, 'value': best_value, 'groups': best_groups}\n",
    "\n",
    "# Create a terminal node value\n",
    "def to_terminal(group):\n",
    "    outcomes = group[:, -1]\n",
    "    return np.bincount(outcomes.astype(int)).argmax()\n",
    "\n",
    "# Recursive function to split the dataset and build the tree\n",
    "def split(node, max_depth, min_size, depth):\n",
    "    left, right = node['groups']\n",
    "    del(node['groups'])\n",
    "\n",
    "    # Check if either group is empty\n",
    "    if len(left) == 0 or len(right) == 0:\n",
    "        node['left'] = node['right'] = to_terminal(np.vstack((left, right)))\n",
    "        return\n",
    "\n",
    "    # Check for maximum depth\n",
    "    if depth >= max_depth:\n",
    "        node['left'], node['right'] = to_terminal(left), to_terminal(right)\n",
    "        return\n",
    "\n",
    "    # Process left child\n",
    "    if len(left) <= min_size:\n",
    "        node['left'] = to_terminal(left)\n",
    "    else:\n",
    "        node['left'] = get_split(left)\n",
    "        split(node['left'], max_depth, min_size, depth + 1)\n",
    "\n",
    "    # Process right child\n",
    "    if len(right) <= min_size:\n",
    "        node['right'] = to_terminal(right)\n",
    "    else:\n",
    "        node['right'] = get_split(right)\n",
    "        split(node['right'], max_depth, min_size, depth + 1)\n",
    "\n",
    "# Build a decision tree\n",
    "def build_tree(train, max_depth, min_size):\n",
    "    root = get_split(train)\n",
    "    split(root, max_depth, min_size, 1)\n",
    "    return root\n",
    "\n",
    "# Save the trained decision tree using pickle\n",
    "def save_model(tree, model_path):\n",
    "    with open(model_path, 'wb') as f:\n",
    "        pickle.dump(tree, f)\n",
    "    print(f\"Model saved to {model_path}\")\n",
    "\n",
    "# Make a prediction with a decision tree\n",
    "def predict(node, row):\n",
    "    if row[node['index']] < node['value']:\n",
    "        if isinstance(node['left'], dict):\n",
    "            return predict(node['left'], row)\n",
    "        else:\n",
    "            return node['left']\n",
    "    else:\n",
    "        if isinstance(node['right'], dict):\n",
    "            return predict(node['right'], row)\n",
    "        else:\n",
    "            return node['right']\n",
    "\n",
    "# Load and prepare the real dataset\n",
    "def load_real_data(file_path):\n",
    "    data = pd.read_csv(file_path)\n",
    "    return data.values  # Return as a NumPy array directly\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Load the preprocessed data\n",
    "    data_path = r'C:\\Users\\ASUS\\Desktop\\Ayush_Sharma_A1\\decision_tree_task\\data\\preprocessed_training_data.csv'\n",
    "    dataset = load_real_data(data_path)\n",
    "    print(\"Data loaded.\")\n",
    "    \n",
    "    # Use a smaller subset of the data for testing\n",
    "    data_sample = pd.DataFrame(dataset).sample(n=1000, random_state=42)\n",
    "    dataset = data_sample.values  # Keep it as a NumPy array for processing\n",
    "    \n",
    "    print(f\"Testing with {len(dataset)} rows (subset of the data).\")\n",
    "    \n",
    "    # Define max depth and min size\n",
    "    max_depth = 2\n",
    "    min_size = 300\n",
    "    print(f\"Max depth: {max_depth}, Min size: {min_size}\")\n",
    "    \n",
    "    # Train the decision tree on the smaller subset\n",
    "    tree = build_tree(dataset, max_depth, min_size)\n",
    "    print(\"Decision Tree trained on the subset of data.\")\n",
    "    \n",
    "    # Save the trained model\n",
    "    model_path = '../models/decision_tree_model_test.pkl'\n",
    "    save_model(tree, model_path)\n",
    "    \n",
    "    # Make a prediction on a sample row from the subset\n",
    "    sample_row = dataset[0][:-1]  # Take the first row, excluding the class label\n",
    "    prediction = predict(tree, sample_row)\n",
    "    print(f\"Prediction for the first row: {prediction}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
